{"cells":[{"cell_type":"code","execution_count":null,"id":"YtuRSa39VPpE","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13975,"status":"ok","timestamp":1672386591524,"user":{"displayName":"uptp capstone","userId":"09467836942660736266"},"user_tz":-480},"id":"YtuRSa39VPpE","outputId":"cdabb074-f339-4937-fcf9-b4046ae890d8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"id":"72111f94","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"72111f94","outputId":"0780c0eb-ed7c-43b7-b6b7-cdfca40fbf0d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 5269 images belonging to 6 classes.\n"]}],"source":["import tensorflow as tf\n","from tensorflow import keras\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","# Define the transformations to apply to the images\n","datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","img_size=227\n","Batch_size=64\n","# Load the dataset and split it into training and test sets\n","data_generator = datagen.flow_from_directory(\n","    '/content/drive/MyDrive/Datasets/White Background/Photos Capstone',\n","    target_size=(img_size, img_size),\n","    batch_size=Batch_size,\n","    class_mode='categorical'\n",")\n","\n","# Initialize empty arrays to hold the images and labels\n","X = np.empty((0, img_size, img_size, 3))\n","y = np.empty((0, 6))\n","\n","# Iterate over the entire dataset\n","for x, label in data_generator:\n","    # Concatenate the images and labels to the arrays\n","    X = np.concatenate((X, x))\n","    y = np.concatenate((y, label))\n","    # Break the loop when all images have been processed\n","    if len(X) == data_generator.n:\n","        break\n","        \n","# Split the data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"]},{"cell_type":"code","execution_count":null,"id":"f2e286b5","metadata":{"id":"f2e286b5"},"outputs":[],"source":["def identity_block(x, filter):\n","    # copy tensor to variable called x_skip\n","    x_skip = x\n","    # Layer 1\n","    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n","    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n","    x = tf.keras.layers.Activation('relu')(x)\n","    # Layer 2\n","    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n","    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n","    # Add Residue\n","    x = tf.keras.layers.Add()([x, x_skip])     \n","    x = tf.keras.layers.Activation('relu')(x)\n","    return x"]},{"cell_type":"code","execution_count":null,"id":"35ac5680","metadata":{"id":"35ac5680"},"outputs":[],"source":["def convolutional_block(x, filter):\n","    # copy tensor to variable called x_skip\n","    x_skip = x\n","    # Layer 1\n","    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same', strides = (2,2))(x)\n","    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n","    x = tf.keras.layers.Activation('relu')(x)\n","    # Layer 2\n","    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n","    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n","    # Processing Residue with conv(1,1)\n","    x_skip = tf.keras.layers.Conv2D(filter, (1,1), strides = (2,2))(x_skip)\n","    # Add Residue\n","    x = tf.keras.layers.Add()([x, x_skip])     \n","    x = tf.keras.layers.Activation('relu')(x)\n","    return x"]},{"cell_type":"code","execution_count":null,"id":"d5a3e88f","metadata":{"id":"d5a3e88f"},"outputs":[],"source":["def ResNet34(shape = (img_size, img_size, 3), classes = 6):\n","    # Step 1 (Setup Input Layer)\n","    x_input = tf.keras.layers.Input(shape)\n","    x = tf.keras.layers.ZeroPadding2D((3, 3))(x_input)\n","    # Step 2 (Initial Conv layer along with maxPool)\n","    x = tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same')(x)\n","    x = tf.keras.layers.BatchNormalization()(x)\n","    x = tf.keras.layers.Activation('relu')(x)\n","    x = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n","    # Define size of sub-blocks and initial filter size\n","    block_layers = [3, 4, 6, 3]\n","    filter_size = 64\n","    # Step 3 Add the Resnet Blocks\n","    for i in range(4):\n","        if i == 0:\n","            # For sub-block 1 Residual/Convolutional block not needed\n","            for j in range(block_layers[i]):\n","                x = identity_block(x, filter_size)\n","        else:\n","            # One Residual/Convolutional Block followed by Identity blocks\n","            # The filter size will go on increasing by a factor of 2\n","            filter_size = filter_size*2\n","            x = convolutional_block(x, filter_size)\n","            for j in range(block_layers[i] - 1):\n","                x = identity_block(x, filter_size)\n","    # Step 4 End Dense Network\n","    x = tf.keras.layers.AveragePooling2D((2,2), padding = 'same')(x)\n","    x = tf.keras.layers.Flatten()(x)\n","    x = tf.keras.layers.Dense(512, activation = 'relu')(x)\n","    x = tf.keras.layers.Dense(classes, activation = 'softmax')(x)\n","    model = tf.keras.models.Model(inputs = x_input, outputs = x, name = \"ResNet34\")\n","    return model"]},{"cell_type":"code","execution_count":null,"id":"77663923","metadata":{"id":"77663923","outputId":"5b6e52d9-9f7f-458c-fde8-8a8ff92d1893"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n"," 5/66 [=>............................] - ETA: 6:40 - loss: 26.8901 - accuracy: 0.2125"]}],"source":["#Sequential\n","model = ResNet34(shape = (img_size, img_size, 3), classes = 6)\n","# Compile the model with the loss function and optimizer\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train the model and store the training history\n","history = model.fit(X_train, y_train, epochs=10, batch_size=Batch_size, validation_data=(X_test, y_test))\n"]},{"cell_type":"code","execution_count":null,"id":"fac29173","metadata":{"id":"fac29173"},"outputs":[],"source":["# Plot the training and validation accuracy\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('Model accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Test'], loc='upper left')\n","plt.show()\n","\n","# Plot the training and validation loss\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Test'], loc='upper left')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"4d7aba1f","metadata":{"id":"4d7aba1f"},"outputs":[],"source":["model.save('/content/drive/MyDrive/Models/resNet_white_10_epoch.h5') "]},{"cell_type":"code","execution_count":null,"id":"d39b614b","metadata":{"id":"d39b614b"},"outputs":[],"source":["# from keras.models import load_model\n","# model = load_model('/content/drive/MyDrive/Models/resNet_white_10_epoch.h5')"]},{"cell_type":"code","execution_count":null,"id":"74d5419e","metadata":{"id":"74d5419e"},"outputs":[],"source":["import pathlib\n","class_names = (data_generator.class_indices)\n","class_names = list((k) for k,v in class_names.items())\n","img = pathlib.Path('Testing\\\\pastel_mandio1.jpg') \n","\n","img = tf.keras.utils.load_img(\n","    img, target_size=(img_size, img_size)\n",")\n","img_array = tf.keras.utils.img_to_array(img)\n","img_array = tf.expand_dims(img_array, 0) # Create a batch\n","\n","predictions = model.predict(img_array)\n","# score = tf.nn.softmax(predictions[0])\n","\n","# # print(\n","# #     \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n","# #     .format(class_names[np.argmax(score)], predictions[0])\n","# # )\n","# # print(class_names[np.argmax(score)], predictions[0])\n","# print('Name: ', class_names[np.argmax(score)], 'Conf: ', np.argmax(predictions[0]))\n","score_index = tf.argmax(predictions[0])\n","score =  predictions[0, score_index]\n","print('Class : ' , class_names[score_index], 'Conf: ', score)"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":5}